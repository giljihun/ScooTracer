//
//  RidingViewModel.swift
//  ScooTracer
//
//  Created by mobicom on 12/10/24.
//

import UIKit
import AVFoundation
import Vision

class RidingViewModel: NSObject, AVCapturePhotoCaptureDelegate {

    // MARK: - Callbacks
    var onPermissionGranted: (() -> Void)?
    var onPermissionDenied: (() -> Void)?
    var onCameraSessionConfigured: ((AVCaptureSession) -> Void)?
    var onPhotoCaptured: ((Result<UIImage, Error>) -> Void)?

    private var captureSession: AVCaptureSession?
    private let photoOutput = AVCapturePhotoOutput() // ì‚¬ì§„ ì¶œë ¥ì„ ìœ„í•œ Output
    private var selfiePhoto: UIImage?
    private var errorCount = 0
    private let faceNetService = FaceNetService()

    override init() {
        super.init()
        selfiePhoto = loadSelfiePhotoFromKeychain()
    }

    // MARK: - Keychainì—ì„œ SelfiePhoto ë¡œë“œ
    private func loadSelfiePhotoFromKeychain() -> UIImage? {
        let query: [String: Any] = [
            kSecClass as String: kSecClassGenericPassword,
            kSecAttrAccount as String: "selfiePhoto",
            kSecReturnData as String: true,
            kSecMatchLimit as String: kSecMatchLimitOne
        ]

        var dataTypeRef: AnyObject?

        let status = SecItemCopyMatching(query as CFDictionary, &dataTypeRef)

        guard status == errSecSuccess, let data = dataTypeRef as? Data else {
            print("Keychainì—ì„œ selfiePhotoë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ì½”ë“œ: \(status)")
            return nil
        }

        return UIImage(data: data)
    }

    // MARK: - ì–¼êµ´ ë¹„êµ
    func compareFace(with image: UIImage, completion: @escaping (Float?, Int) -> Void) {
        guard let croppedFace = cropFaceFromImage(image) else {
            print("ğŸš¨ ì–¼êµ´ í¬ë¡­ ì‹¤íŒ¨: cropFaceFromImage ê²°ê³¼ê°€ nil")
            completion(nil, errorCount)
            return
        }

        guard let selfiePhoto = selfiePhoto else {
            print("ğŸš¨ Keychainì—ì„œ selfiePhoto ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨")
            completion(nil, errorCount)
            return
        }

        guard let resizedCurrent = croppedFace.resized(to: CGSize(width: 160, height: 160)) else { return }

        guard let resizedSelfie = selfiePhoto.resized(to: CGSize(width: 160, height: 160)) else { return }

        let similarity = faceNetService?.compare(image1: resizedSelfie, image2: resizedCurrent)
        if let similarity = similarity, similarity < 0.6 {
            errorCount += 1
        }

        print("âœ… ì–¼êµ´ ë¹„êµ ì„±ê³µ: similarity = \(similarity ?? 0)")
        completion(similarity, errorCount)
    }


    // MARK: - ì–¼êµ´ í¬ë¡­
    private func cropFaceFromImage(_ image: UIImage, targetAspectRatio: CGFloat = 1.0) -> UIImage? {
        guard let cgImage = image.correctedOrientation()?.cgImage else {
            print("ğŸš¨ ì´ë¯¸ì§€ cgImage ë³€í™˜ ì‹¤íŒ¨")
            return nil
        }

        let request = VNDetectFaceRectanglesRequest()
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])

        do {
            try handler.perform([request])
            guard let firstFace = request.results?.first else {
                print("ğŸš¨ Vision ìš”ì²­ ì‹¤íŒ¨: ì–¼êµ´ ê°ì§€ ê²°ê³¼ ì—†ìŒ")
                return nil
            }

            // ì–¼êµ´ ì˜ì—­ ê³„ì‚°
            let faceRect = calculateFaceRect(
                firstFace.boundingBox,
                imageSize: CGSize(width: cgImage.width, height: cgImage.height),
                targetAspectRatio: targetAspectRatio
            )

            // ì–¼êµ´ í¬ë¡­
            guard let croppedImage = cropImage(image, to: faceRect) else {
                print("ğŸš¨ ì–¼êµ´ í¬ë¡­ ì‹¤íŒ¨")
                return nil
            }

            print("âœ… ì–¼êµ´ í¬ë¡­ ì„±ê³µ")
            return croppedImage
        } catch {
            print("ğŸš¨ Vision ìš”ì²­ ì˜¤ë¥˜: \(error.localizedDescription)")
            return nil
        }
    }


    private func calculateFaceRect(_ boundingBox: CGRect, imageSize: CGSize, targetAspectRatio: CGFloat) -> CGRect {
        // Vision ì¢Œí‘œê³„ë¥¼ UIKit ì¢Œí‘œê³„ë¡œ ë³€í™˜
        let x = boundingBox.origin.x * imageSize.width
        let y = (1.0 - boundingBox.origin.y - boundingBox.height) * imageSize.height
        let width = boundingBox.width * imageSize.width
        let height = boundingBox.height * imageSize.height

        var rect = CGRect(x: x, y: y, width: width, height: height)

        // ë¹„ìœ¨ì— ë§ì¶° ì˜ì—­ í™•ì¥
        let currentAspectRatio = rect.width / rect.height
        if currentAspectRatio > targetAspectRatio {
            // í˜„ì¬ ì˜ì—­ì´ ë” ë„“ìŒ â†’ ì„¸ë¡œë¥¼ í™•ì¥
            let newHeight = rect.width / targetAspectRatio
            let heightDiff = newHeight - rect.height
            rect.origin.y -= heightDiff / 2
            rect.size.height = newHeight
        } else {
            // í˜„ì¬ ì˜ì—­ì´ ë” ì¢ìŒ â†’ ì¢Œìš°ë¥¼ í™•ì¥
            let newWidth = rect.height * targetAspectRatio
            let widthDiff = newWidth - rect.width
            rect.origin.x -= widthDiff / 2
            rect.size.width = newWidth
        }

        // ì¶”ê°€ í™•ì¥ (ì „ì²´ì ìœ¼ë¡œ í‚¤ìš°ê¸°)
        let expansionFactor: CGFloat = 0.2 // ì–¼êµ´ì„ ì¡°ê¸ˆ ë” í‚¤ìš°ê¸°
        rect = rect.insetBy(dx: -rect.width * expansionFactor, dy: -rect.height * expansionFactor)

        // ì›ë³¸ ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì¡°ì •
        let imageBounds = CGRect(x: 0, y: 0, width: imageSize.width, height: imageSize.height)
        return rect.intersection(imageBounds)
    }

    private func cropImage(_ image: UIImage, to rect: CGRect) -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }

        // í¬ë¡­ ì˜ì—­ ê³„ì‚°
        guard let croppedCgImage = cgImage.cropping(to: rect) else {
            print("í¬ë¡­ ì˜ì—­ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return nil
        }

        // UIImageë¡œ ë°˜í™˜
        return UIImage(cgImage: croppedCgImage, scale: image.scale, orientation: image.imageOrientation)
    }

    // MARK: - ì¹´ë©”ë¼ ê¶Œí•œ í™•ì¸
    func checkCameraAuthorization() {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            onPermissionGranted?()
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { [weak self] granted in
                DispatchQueue.main.async {
                    granted ? self?.onPermissionGranted?() : self?.onPermissionDenied?()
                }
            }
        default:
            onPermissionDenied?()
        }
    }

    // MARK: - ì¹´ë©”ë¼ ì„¸ì…˜ ì„¤ì •
    func setupCameraSession() {
        let session = AVCaptureSession()
        session.sessionPreset = .photo

        guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front),
              let input = try? AVCaptureDeviceInput(device: camera) else {
            print("ì „ë©´ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        }

        session.addInput(input)

        // Photo Output ì¶”ê°€
        if session.canAddOutput(photoOutput) {
            session.addOutput(photoOutput)
        }

        captureSession = session
        onCameraSessionConfigured?(session)
    }

    // MARK: - ì‚¬ì§„ ìº¡ì²˜
    func capturePhoto(completion: @escaping (Result<UIImage, Error>) -> Void) {
        let settings = AVCapturePhotoSettings()
        settings.flashMode = .off
        photoOutput.capturePhoto(with: settings, delegate: self)
    }

    // MARK: - AVCapturePhotoCaptureDelegate
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            print("ì‚¬ì§„ ì²˜ë¦¬ ì‹¤íŒ¨: \(error.localizedDescription)")
            onPhotoCaptured?(.failure(error)) // ì‹¤íŒ¨ ì‹œ .failure ì „ë‹¬
            return
        }

        guard let photoData = photo.fileDataRepresentation(),
              let image = UIImage(data: photoData)?.correctedOrientation() else {
            print("ì‚¬ì§„ ë°ì´í„°ë¥¼ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            let conversionError = NSError(domain: "CaptureError", code: -1, userInfo: [NSLocalizedDescriptionKey: "ì‚¬ì§„ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨"])
            onPhotoCaptured?(.failure(conversionError)) // ë³€í™˜ ì‹¤íŒ¨ ì‹œ .failure ì „ë‹¬
            return
        }

        onPhotoCaptured?(.success(image)) // ì„±ê³µ ì‹œ .success ì „ë‹¬
    }


    // MARK: - ì¹´ë©”ë¼ ì„¸ì…˜ ì œì–´
    func startCameraSession() {
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.captureSession?.startRunning()
        }
    }

    func stopCameraSession() {
        captureSession?.stopRunning()
    }
}
